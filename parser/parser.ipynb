{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874abf8-00be-46cc-b1b7-f981e9d591fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "\n",
    "TERMINALS = \"\"\"\n",
    "Adj -> \"country\" | \"dreadful\" | \"enigmatical\" | \"little\" | \"moist\" | \"red\"\n",
    "Adv -> \"down\" | \"here\" | \"never\"\n",
    "Conj -> \"and\" | \"until\"\n",
    "Det -> \"a\" | \"an\" | \"his\" | \"my\" | \"the\"\n",
    "N -> \"armchair\" | \"companion\" | \"day\" | \"door\" | \"hand\" | \"he\" | \"himself\"\n",
    "N -> \"holmes\" | \"home\" | \"i\" | \"mess\" | \"paint\" | \"palm\" | \"pipe\" | \"she\"\n",
    "N -> \"smile\" | \"thursday\" | \"walk\" | \"we\" | \"word\"\n",
    "P -> \"at\" | \"before\" | \"in\" | \"of\" | \"on\" | \"to\"\n",
    "V -> \"arrived\" | \"came\" | \"chuckled\" | \"had\" | \"lit\" | \"said\" | \"sat\"\n",
    "V -> \"smiled\" | \"tell\" | \"were\"\n",
    "\"\"\"\n",
    "\n",
    "NONTERMINALS = \"\"\"\n",
    "S -> N V | NP VP | VP NP | VP Conj NP | VP NP Conj NP | VP NP Conj VP NP | VP Conj VP | S Conj S\n",
    "NP -> N | N N | Det N | Det Adj N | Adj N | P N | Det N P | P Det N | Det N Adv\n",
    "VP -> V | VP NP | VP P NP | VP Det NP | VP Conj VP | Adv VP | VP Adv\n",
    "Adj -> Adj Adj | Adj Adj Adj\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(NONTERMINALS + TERMINALS)\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        # If filename specified, read sentence from file\n",
    "        if len(sys.argv) == 2:\n",
    "            with open(sys.argv[1]) as f:\n",
    "                s = f.read()\n",
    "\n",
    "        # Otherwise, get sentence as input\n",
    "        else:\n",
    "            s = input(\"Sentence: \")\n",
    "            \n",
    "        if s == \"q\": quit()\n",
    "\n",
    "        # Convert input into list of words\n",
    "        s = preprocess(s)\n",
    "\n",
    "        # Attempt to parse sentence\n",
    "        try:\n",
    "            trees = list(parser.parse(s))\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            return\n",
    "        if not trees:\n",
    "            print(\"Could not parse sentence.\")\n",
    "            #return\n",
    "        else:\n",
    "            # Print each tree with noun phrase chunks\n",
    "            for tree in trees:\n",
    "                tree.pretty_print()\n",
    "\n",
    "                print(\"Noun Phrase Chunks\")\n",
    "                for np in np_chunk(tree):\n",
    "                    print(\" \".join(np.flatten()))\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    \"\"\"\n",
    "    Convert `sentence` to a list of its words.\n",
    "    Pre-process sentence by converting all characters to lowercase\n",
    "    and removing any word that does not contain at least one alphabetic\n",
    "    character.\n",
    "    \"\"\"\n",
    "    # CG: make the sentence all lowercase and tokenize it:\n",
    "    tokenized_sentence = nltk.tokenize.word_tokenize(sentence.lower())\n",
    "\n",
    "    # CG: create a copy to iter over:\n",
    "    working_sentence = tokenized_sentence.copy()\n",
    "\n",
    "    # Loop over all words in the copy of the tokenized list:\n",
    "    for aword in working_sentence:\n",
    "\n",
    "        # CG: let's initialize our indicator as False:\n",
    "        word_is_OK = False\n",
    "\n",
    "        # CG: loop over all chars in a word:\n",
    "        for achar in aword:\n",
    "\n",
    "            # CG: check if there are alphabetic characters in the word:\n",
    "            if achar in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "\n",
    "                # CG: if there are, make signal to True:\n",
    "                word_is_OK = True\n",
    "\n",
    "        # CG: Any word that doesnâ€™t contain at least one alphabetic character (e.g. . or 28) should be excluded from the returned list:\n",
    "        if not word_is_OK:\n",
    "\n",
    "            # CG: remove the word from the list:\n",
    "            tokenized_sentence.remove (aword)\n",
    "\n",
    "    # CG: return the tokenized sentence:\n",
    "    return tokenized_sentence\n",
    "\n",
    "\n",
    "def np_chunk(tree):\n",
    "    \"\"\"\n",
    "    Return a list of all noun phrase chunks in the sentence tree.\n",
    "    A noun phrase chunk is defined as any subtree of the sentence\n",
    "    whose label is \"NP\" that does not itself contain any other\n",
    "    noun phrases as subtrees.\n",
    "    \"\"\"\n",
    "    # CG: initialize resulting list:\n",
    "    result = []\n",
    "\n",
    "    # CG: loop over all 3rd-level branches of a tree:\n",
    "    for subtree in tree.subtrees(filter=lambda st: st.label() == 'NP'):\n",
    "\n",
    "        # CG: a noun phrase chunk is a subtree of the original tree whose label is NP and that does not itself contain other noun phrases as subtrees. \n",
    "        # CG: place all subtrees' subtrees that contain 'NP' in a string:\n",
    "        string_subtree=str(list(subtree.subtrees(lambda st: st.label() == 'NP')))\n",
    "\n",
    "        # CG: ... and use string count() method to check if there's no other 'NP' contained in an 'NP':\n",
    "        if string_subtree.count('NP') == 1:\n",
    "\n",
    "            # CG: make sure it does not repeat in the result:\n",
    "            if subtree not in result:\n",
    "\n",
    "                # CG: add the subtree branch to the resulting list:\n",
    "                result.append (subtree)\n",
    "\n",
    "    # CG: return the resulting list:\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def np_chunk_(tree):\n",
    "    \"\"\"\n",
    "    Return a list of all noun phrase chunks in the sentence tree.\n",
    "    A noun phrase chunk is defined as any subtree of the sentence\n",
    "    whose label is \"NP\" that does not itself contain any other\n",
    "    noun phrases as subtrees.\n",
    "    \"\"\"\n",
    "    # CG: initialize resulting list:\n",
    "    result = []\n",
    "\n",
    "    # CG: loop over all 3rd-level branches of a tree:\n",
    "    for subtree in tree.subtrees(filter=lambda t: t.height() == 3):\n",
    "\n",
    "        # CG: check if the subtree is an NP:\n",
    "        if subtree.label() == 'NP':\n",
    "\n",
    "            # CG: make sure it does not repeat in the result:\n",
    "            if subtree not in result:\n",
    "                \n",
    "                # CG: add the subtree branch to the resulting list:\n",
    "                result.append (subtree)\n",
    "\n",
    "    # CG: return the resulting list:\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6b078-f7f7-4bbf-bc4d-56a60dd9e351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
