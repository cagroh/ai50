{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874abf8-00be-46cc-b1b7-f981e9d591fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Anaconda3\\envs\\ai50\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sentence:  cats run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      S     \n",
      "  ____|___   \n",
      " NP       | \n",
      " |        |  \n",
      " N        V \n",
      " |        |  \n",
      "cats     run\n",
      "\n",
      "Noun Phrase Chunks\n",
      "cats\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sentence:  Cats climb trees\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse sentence.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sentence:  Small cats run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           S      \n",
      "        ___|____   \n",
      "       NP       | \n",
      "   ____|___     |  \n",
      "  |        NP   | \n",
      "  |        |    |  \n",
      "  A        N    V \n",
      "  |        |    |  \n",
      "small     cats run\n",
      "\n",
      "Noun Phrase Chunks\n",
      "cats\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sentence:  Small white cats climb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S            \n",
      "         ____|_________    \n",
      "        NP             |  \n",
      "   _____|____          |   \n",
      "  |          NP        |  \n",
      "  |      ____|___      |   \n",
      "  |     |        NP    |  \n",
      "  |     |        |     |   \n",
      "  A     A        N     V  \n",
      "  |     |        |     |   \n",
      "small white     cats climb\n",
      "\n",
      "Noun Phrase Chunks\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "\n",
    "TERMINALS = \"\"\"\n",
    "A -> \"small\" | \"white\"\n",
    "N -> \"cats\" | \"trees\"\n",
    "V -> \"climb\" | \"run\"\n",
    "\"\"\"\n",
    "\n",
    "NONTERMINALS = \"\"\"\n",
    "S -> NP V\n",
    "NP -> N | A NP\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(NONTERMINALS + TERMINALS)\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        # If filename specified, read sentence from file\n",
    "        if len(sys.argv) == 2:\n",
    "            with open(sys.argv[1]) as f:\n",
    "                s = f.read()\n",
    "\n",
    "        # Otherwise, get sentence as input\n",
    "        else:\n",
    "            s = input(\"Sentence: \")\n",
    "            \n",
    "        if s == \"q\": quit()\n",
    "\n",
    "        # Convert input into list of words\n",
    "        s = preprocess(s)\n",
    "\n",
    "        # Attempt to parse sentence\n",
    "        try:\n",
    "            trees = list(parser.parse(s))\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            return\n",
    "        if not trees:\n",
    "            print(\"Could not parse sentence.\")\n",
    "            #return\n",
    "        else:\n",
    "            # Print each tree with noun phrase chunks\n",
    "            for tree in trees:\n",
    "                tree.pretty_print()\n",
    "\n",
    "                print(\"Noun Phrase Chunks\")\n",
    "                for np in np_chunk(tree):\n",
    "                    print(\" \".join(np.flatten()))\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    \"\"\"\n",
    "    Convert `sentence` to a list of its words.\n",
    "    Pre-process sentence by converting all characters to lowercase\n",
    "    and removing any word that does not contain at least one alphabetic\n",
    "    character.\n",
    "    \"\"\"\n",
    "    # CG: make the sentence all lowercase and tokenize it:\n",
    "    tokenized_sentence = nltk.tokenize.word_tokenize(sentence.lower())\n",
    "\n",
    "    # CG: create a copy to iter over:\n",
    "    working_sentence = tokenized_sentence.copy()\n",
    "\n",
    "    # Loop over all words in the copy of the tokenized list:\n",
    "    for aword in working_sentence:\n",
    "\n",
    "        # CG: let's initialize our indicator as False:\n",
    "        word_is_OK = False\n",
    "\n",
    "        # CG: loop over all chars in a word:\n",
    "        for achar in aword:\n",
    "\n",
    "            # CG: check if there are alphabetic characters in the word:\n",
    "            if achar in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "\n",
    "                # CG: if there are, make signal to True:\n",
    "                word_is_OK = True\n",
    "\n",
    "        # CG: Any word that doesnâ€™t contain at least one alphabetic character (e.g. . or 28) should be excluded from the returned list:\n",
    "        if not word_is_OK:\n",
    "\n",
    "            # CG: remove the word from the list:\n",
    "            tokenized_sentence.remove (aword)\n",
    "\n",
    "    # CG: return the tokenized sentence:\n",
    "    return tokenized_sentence\n",
    "\n",
    "\n",
    "def np_chunk(tree):\n",
    "    \"\"\"\n",
    "    Return a list of all noun phrase chunks in the sentence tree.\n",
    "    A noun phrase chunk is defined as any subtree of the sentence\n",
    "    whose label is \"NP\" that does not itself contain any other\n",
    "    noun phrases as subtrees.\n",
    "    \"\"\"\n",
    "    # CG: initialize resulting list:\n",
    "    result = []\n",
    "\n",
    "    # CG: loop over all 3rd-level branches of a tree:\n",
    "    for subtree in tree.subtrees(filter=lambda st: st.label() == 'NP'):\n",
    "\n",
    "        # CG: a noun phrase chunk is a subtree of the original tree whose label is NP and that does not itself contain other noun phrases as subtrees. \n",
    "        # CG: place all subtrees' subtrees that contain 'NP' in a string:\n",
    "        string_subtree=str(list(subtree.subtrees(lambda st: st.label() == 'NP')))\n",
    "\n",
    "        # CG: ... and use string count() method to check if there's no other 'NP' contained in an 'NP':\n",
    "        if string_subtree.count('NP') == 1:\n",
    "\n",
    "            # CG: make sure it does not repeat in the result:\n",
    "            if subtree not in result:\n",
    "\n",
    "                # CG: add the subtree branch to the resulting list:\n",
    "                result.append (subtree)\n",
    "\n",
    "    # CG: return the resulting list:\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def np_chunk_(tree):\n",
    "    \"\"\"\n",
    "    Return a list of all noun phrase chunks in the sentence tree.\n",
    "    A noun phrase chunk is defined as any subtree of the sentence\n",
    "    whose label is \"NP\" that does not itself contain any other\n",
    "    noun phrases as subtrees.\n",
    "    \"\"\"\n",
    "    # CG: initialize resulting list:\n",
    "    result = []\n",
    "\n",
    "    # CG: loop over all 3rd-level branches of a tree:\n",
    "    for subtree in tree.subtrees(filter=lambda t: t.height() == 3):\n",
    "\n",
    "        # CG: check if the subtree is an NP:\n",
    "        if subtree.label() == 'NP':\n",
    "\n",
    "            # CG: make sure it does not repeat in the result:\n",
    "            if subtree not in result:\n",
    "                \n",
    "                # CG: add the subtree branch to the resulting list:\n",
    "                result.append (subtree)\n",
    "\n",
    "    # CG: return the resulting list:\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6b078-f7f7-4bbf-bc4d-56a60dd9e351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
